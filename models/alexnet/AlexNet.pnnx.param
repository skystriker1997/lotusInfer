7767517
22 21
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,224,224)f32
nn.Conv2d                features.0               1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(11,11) out_channels=64 padding=(2,2) padding_mode=zeros stride=(4,4) @bias=(64)f32 @weight=(64,3,11,11)f32 #0=(1,3,224,224)f32 #1=(1,64,55,55)f32
nn.ReLU                  features.1               1 1 1 2 #1=(1,64,55,55)f32 #2=(1,64,55,55)f32
nn.MaxPool2d             features.2               1 1 2 3 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(0,0) return_indices=False stride=(2,2) #2=(1,64,55,55)f32 #3=(1,64,27,27)f32
nn.Conv2d                features.3               1 1 3 4 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(5,5) out_channels=192 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,64,5,5)f32 #3=(1,64,27,27)f32 #4=(1,192,27,27)f32
nn.ReLU                  features.4               1 1 4 5 #4=(1,192,27,27)f32 #5=(1,192,27,27)f32
nn.MaxPool2d             features.5               1 1 5 6 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(0,0) return_indices=False stride=(2,2) #5=(1,192,27,27)f32 #6=(1,192,13,13)f32
nn.Conv2d                features.6               1 1 6 7 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(3,3) out_channels=384 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,192,3,3)f32 #6=(1,192,13,13)f32 #7=(1,384,13,13)f32
nn.ReLU                  features.7               1 1 7 8 #7=(1,384,13,13)f32 #8=(1,384,13,13)f32
nn.Conv2d                features.8               1 1 8 9 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,384,3,3)f32 #8=(1,384,13,13)f32 #9=(1,256,13,13)f32
nn.ReLU                  features.9               1 1 9 10 #9=(1,256,13,13)f32 #10=(1,256,13,13)f32
nn.Conv2d                features.10              1 1 10 11 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 #10=(1,256,13,13)f32 #11=(1,256,13,13)f32
nn.ReLU                  features.11              1 1 11 12 #11=(1,256,13,13)f32 #12=(1,256,13,13)f32
nn.MaxPool2d             features.12              1 1 12 13 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(0,0) return_indices=False stride=(2,2) #12=(1,256,13,13)f32 #13=(1,256,6,6)f32
nn.AdaptiveAvgPool2d     avgpool                  1 1 13 14 output_size=(6,6) #13=(1,256,6,6)f32 #14=(1,256,6,6)f32
torch.flatten            torch.flatten_0          1 1 14 15 end_dim=-1 start_dim=1 $input=14 #14=(1,256,6,6)f32 #15=(1,9216)f32
nn.Linear                classifier.1             1 1 15 16 bias=True in_features=9216 out_features=4096 @bias=(4096)f32 @weight=(4096,9216)f32 #15=(1,9216)f32 #16=(1,4096)f32
nn.ReLU                  classifier.2             1 1 16 17 #16=(1,4096)f32 #17=(1,4096)f32
nn.Linear                classifier.4             1 1 17 18 bias=True in_features=4096 out_features=4096 @bias=(4096)f32 @weight=(4096,4096)f32 #17=(1,4096)f32 #18=(1,4096)f32
nn.ReLU                  classifier.5             1 1 18 19 #18=(1,4096)f32 #19=(1,4096)f32
nn.Linear                classifier.6             1 1 19 20 bias=True in_features=4096 out_features=1000 @bias=(1000)f32 @weight=(1000,4096)f32 #19=(1,4096)f32 #20=(1,1000)f32
pnnx.Output              pnnx_output_0            1 0 20 #20=(1,1000)f32
